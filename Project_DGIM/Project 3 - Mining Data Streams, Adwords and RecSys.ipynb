{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c461633a",
   "metadata": {},
   "source": [
    "### Enter full names of group members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4648c5",
   "metadata": {},
   "source": [
    "##### Name A: Dominik Ucher\n",
    "##### Name B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d55dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from sympy import prime\n",
    "from pathlib import Path  # for paths of files\n",
    "import csv\n",
    "import copy\n",
    "import random\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ANSI escape codes for colors\n",
    "class colors:\n",
    "    red = '\\033[91m'\n",
    "    green = '\\033[92m'\n",
    "    blue = '\\033[94m'\n",
    "    end = '\\033[0m'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4a780",
   "metadata": {},
   "source": [
    "### 1. DGIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287695e",
   "metadata": {},
   "source": [
    "#### 1.1. DGIM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af55744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default DGIM parameters\n",
    "\n",
    "stream_path = 'data/my_stream.txt'\n",
    "\n",
    "# The window size\n",
    "N = 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f339cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBucket(bucketList, end_time_stamp):\n",
    "    for i in range (len(bucketList) - 1):\n",
    "        if len(bucketList[i]) > 2:\n",
    "            oldtime = bucketList[i].pop(0)\n",
    "            secondoldtime = bucketList[i].pop(0)\n",
    "            bucketList[i+1].append(secondoldtime)\n",
    "\n",
    "def checkTime(bucketList, end_time_stamp):\n",
    "    for bucket in bucketList:\n",
    "        for time in bucket:\n",
    "            if (end_time_stamp - time) > N:\n",
    "                bucket.remove(time)\n",
    "\n",
    "\n",
    "def dgim_algorithm(stream_path, N):\n",
    "    \n",
    "    # Create the buckets and initialize the timestamp\n",
    "    k = int(N).bit_length()\n",
    "    bucket_list = [[] for _ in range(k)]\n",
    "    end_time_stamp = 0\n",
    "    \n",
    "    # Loop through the entire data stream, one bit at a time\n",
    "    with open(stream_path) as f:\n",
    "        while True:\n",
    "            bit = f.read(1)\n",
    "            \n",
    "            # Clause to break while loop at the end of the stream\n",
    "            if not bit:\n",
    "                break\n",
    "\n",
    "            # To-do! update timestamp\n",
    "            end_time_stamp += 1\n",
    "            \n",
    "            # To-do! implement the dgim algorithm here\n",
    "            if bit == '1':\n",
    "                bucket_list[0].append(end_time_stamp)\n",
    "                checkBucket(bucket_list, end_time_stamp)\n",
    "                checkTime(bucket_list, end_time_stamp)\n",
    "\n",
    "        # for i, bucket in enumerate(bucket_list):\n",
    "        #     bucket_list[i] = [time % N for time in bucket]\n",
    "\n",
    "    return bucket_list, end_time_stamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc1d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = dgim_algorithm(stream_path, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6966be95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated list of timestamps buckets from DGIM algorithm: \n",
      " [[1010099], [1010091, 1010096], [1010083, 1010089], [1010063, 1010075], [1010044], [1010006], [1009821, 1009946], [1009688], []]\n",
      "The end timestamp: 1010102\n"
     ]
    }
   ],
   "source": [
    "print(f\"The updated list of timestamps buckets from DGIM algorithm: \\n {bucket[0]}\")\n",
    "print(f\"The end timestamp: {bucket[1]}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c273257",
   "metadata": {},
   "source": [
    "#### 1.2. Query the Bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb0343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_count(stream_path, k):\n",
    "    stream_list = []\n",
    "    with open(stream_path, 'r') as file:\n",
    "        for line in file:\n",
    "            stream_list.extend(list(map(int, line.strip())))\n",
    "\n",
    "    # Convert the list into a numpy array\n",
    "    stream_array = np.array(stream_list)\n",
    "    \n",
    "    return int(np.sum(stream_array[-k:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7f130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgim_query(bucket, N, k):  \n",
    "\n",
    "    one_count = 0\n",
    "    end_time_stamps = bucket[0]\n",
    "    current_time = bucket[1] - 2\n",
    "    min_time = current_time - k\n",
    "    valid_times = []\n",
    "\n",
    "    for i in range(len(end_time_stamps)):\n",
    "        for bucket in end_time_stamps[i]:\n",
    "            if min_time <= bucket:\n",
    "                valid_times.append(2**i)\n",
    "\n",
    "    valid_times[-1] = valid_times[-1] / 2\n",
    "\n",
    "    one_count = sum(valid_times)\n",
    "    \n",
    "    \n",
    "    return math.ceil(one_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "387e5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of queries\n",
    "K = [10, 50, 100, 300, 500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7702bc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "The total 1s in the last 10 bits by DGIM: 4\n",
      "The true count of 1s in the last 10 bits: 5\n",
      "The DGIM error for predicted 1s in the last 10 bits:     20.0 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 50 bits by DGIM: 25\n",
      "The true count of 1s in the last 50 bits: 26\n",
      "The DGIM error for predicted 1s in the last 50 bits:     3.85 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 100 bits by DGIM: 61\n",
      "The true count of 1s in the last 100 bits: 51\n",
      "The DGIM error for predicted 1s in the last 100 bits:     19.61 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 300 bits by DGIM: 173\n",
      "The true count of 1s in the last 300 bits: 150\n",
      "The DGIM error for predicted 1s in the last 300 bits:     15.33 %\n",
      "---------------------------------------------------------------\n",
      "The total 1s in the last 500 bits by DGIM: 269\n",
      "The true count of 1s in the last 500 bits: 241\n",
      "The DGIM error for predicted 1s in the last 500 bits:     11.62 %\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------\")\n",
    "for k in K:\n",
    "    dgim_count = dgim_query(bucket, 500, k)\n",
    "    true_count = actual_count(stream_path, k)\n",
    "    \n",
    "    print(f\"The total 1s in the last {k} bits by DGIM: {dgim_count}\")\n",
    "    print(f\"The true count of 1s in the last {k} bits: {true_count}\")\n",
    "    print(f\"The DGIM error for predicted 1s in the last {k} bits: \\\n",
    "    {round(abs(100*(dgim_count-true_count))/true_count,2)} %\")\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaaceac",
   "metadata": {},
   "source": [
    "### 2. Bloom filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92883c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Username data for the creation of bloom filters - B\n",
    "data_file = (Path(\"data/bloom_username\").with_suffix('.csv'))\n",
    "\n",
    "# Test data to check the functionality and false positive rate\n",
    "test1_file = (Path(\"data/test1_username\").with_suffix('.csv'))\n",
    "test2_file = (Path(\"data/test2_username\").with_suffix('.csv'))\n",
    "\n",
    "# Default bloom filter parameters\n",
    "bloom_size = 1500000 # parameter N\n",
    "h = 3 # number of hash functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c5e5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of bloom filter with zeros\n",
    "B = np.zeros(bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c033746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73d660",
   "metadata": {},
   "source": [
    "#### 2.1. Create Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75b69edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "def generate_hash(h, N):\n",
    "    hash_list = []\n",
    "    \n",
    "    # To-do! generate a list of hash functions\n",
    "    for _ in range(h):\n",
    "        prime = sympy.randprime(1, 10000)\n",
    "\n",
    "        def hash_func(x, prime=prime, N=N):\n",
    "            hash_value = 0\n",
    "            for i, char in enumerate(x):\n",
    "                hash_value = (hash_value + ord(char) * (prime ** (i + 1))) % N\n",
    "            return hash_value\n",
    "        hash_list.append(hash_func)\n",
    "        \n",
    "    return hash_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a75aeecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = generate_hash(h, bloom_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d2d4c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bloom_filter(B, hashes, data):\n",
    "    with data.open(encoding='utf-8') as f:\n",
    "        for name in f:\n",
    "            \n",
    "            # To-do! update the hash index of the bloom filter with 1s\n",
    "            name = name.strip()\n",
    "            for hash_func in hashes:\n",
    "                index = hash_func(name)\n",
    "                B[index] = 1\n",
    "            \n",
    "\n",
    "            \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe79b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_array = create_bloom_filter(B, hashes, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7ce957d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff48616",
   "metadata": {},
   "source": [
    "#### 2.2. Verify usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "530485d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_verify_username(bloom_array, hashes, new_user):\n",
    "    \n",
    "    # To-do! verify username and return a code of 0 or 1 (1 - username taken and 0 - username available)\n",
    "    for hash_func in hashes:\n",
    "        index = hash_func(new_user)\n",
    "        if (bloom_array[index] == 0):\n",
    "            return 0\n",
    "    \n",
    "        \n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6edf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to test different usernames here\n",
    "\n",
    "new_username = \"KazeemTDT4305\"\n",
    "\n",
    "# new_username = \"ShambaTDT4305\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22690d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code = single_verify_username(bloom_array, hashes, new_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7730361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mUsername KazeemTDT4305 is available. Congrats!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if user_code == 1:\n",
    "    print(colors.red + f\"Username {new_username} has been taken. Try again!\" + colors.end)\n",
    "elif user_code == 0:\n",
    "    print(colors.green + f\"Username {new_username} is available. Congrats!\" + colors.end)\n",
    "else:\n",
    "    print(colors.blue + f\"Wrong pass code. Please reverify!\" + colors.end)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "080d7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_verify_username(bloom_array, hashes, data):\n",
    "    # Initialize counts\n",
    "    total_name = 0\n",
    "    taken_name = 0\n",
    "    \n",
    "    with data.open(encoding = 'utf-8') as f:\n",
    "        for name in f:\n",
    "            # To-do! similar to the single verify, but returns a percentage of usernames taken...\n",
    "            # ...(In other words seen already by the bloom filter during its creation)\n",
    "            name = name.strip()\n",
    "            total_name += 1\n",
    "            is_taken = True\n",
    "\n",
    "            for hash_func in hashes:\n",
    "                index = hash_func(name)\n",
    "                if bloom_array[index] == 0:\n",
    "                    is_taken = False\n",
    "                    break \n",
    "            \n",
    "            if is_taken:\n",
    "                taken_name += 1\n",
    "                \n",
    "            \n",
    "    return round(taken_name/total_name*100,2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4725c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 1: 100.0%\n",
      "----------------------------------------------------------\n",
      "Percentage of username seen before from test 2: 23.74%\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test1_file)\n",
    "print(f\"Percentage of username seen before from test 1: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "user_total = group_verify_username(bloom_array, hashes, test2_file)\n",
    "print(f\"Percentage of username seen before from test 2: {user_total}%\")\n",
    "print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488c00b",
   "metadata": {},
   "source": [
    "### 3. Flajolet-Martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dae74f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flajolet_martin(input_stream):\n",
    "    R = 0  # Initialize maximum rightmost zero bit position to 0\n",
    "\n",
    "    # To-do! Define hash function h(x) = 6x + 1 mod 5\n",
    "    def hash_func(x):\n",
    "        return (6*x + 1) % 5\n",
    "    \n",
    "\n",
    "    # To-do! Iterate over the input stream and update maximum rightmost zero bit position\n",
    "    \n",
    "    def trailing_zeros(x):\n",
    "        if x == 0:\n",
    "            return 1\n",
    "        count = 0\n",
    "        while x & 1 == 0:\n",
    "            count += 1\n",
    "            x >>= 1\n",
    "        return count\n",
    "    \n",
    "    for element in input_stream:\n",
    "        hash_val = hash_func(element)\n",
    "        R = max(R, trailing_zeros(hash_val))\n",
    "    \n",
    "\n",
    "    # Estimate the number of distinct elements\n",
    "    distinct_estimate = 2 ** R\n",
    "\n",
    "    return distinct_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7a283b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 1: 2\n",
      "-----------------------------------------------------\n",
      "Distinct elements (estimated) in input stream 2: 4\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Input stream\n",
    "input_stream1 = [1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1]\n",
    "input_stream2 = [1, 3, 2, 1, 2, 3, 4, 3, 1, 2, 3, 1]\n",
    "\n",
    "# Run the Flajolet-Martin algorithm\n",
    "distinct_estimate1 = flajolet_martin(input_stream1)\n",
    "distinct_estimate2 = flajolet_martin(input_stream2)\n",
    "\n",
    "# Print the estimated number of distinct elements\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 1:\", distinct_estimate1)\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(f\"Distinct elements (estimated) in input stream 2:\", distinct_estimate2)\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3051ee5",
   "metadata": {},
   "source": [
    "### 4. Adword "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b08ba",
   "metadata": {},
   "source": [
    "#### 4.1. Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a58d6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User queries\n",
    "queries = [\"big data\", \"big data\", \"big data\",\"bloom filters\", \"bloom filters\", \"bloom filters\",\n",
    "           \"flajolet martin\", \"flajolet martin\", \"flajolet martin\", \"dgim algorithm\", \"dgim algorithm\", \"dgim algorithm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66ee11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company A B C and D keywords and budget $$$\n",
    "global_companies = {\n",
    "        'A': [\"big data\", \"bloom filters\", 3],\n",
    "        'B': [\"flajolet martin\", 3],\n",
    "        'C': [\"flajolet martin\", \"dgim algorithm\", 3],\n",
    "        'D': [\"big data\", 3],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd6eb986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0\n",
    "    \n",
    "    # To-do! update revenue using greedy algorithm\n",
    "    for word in queries:\n",
    "        valid_companies = [company for company in local_companies if word in local_companies[company][:-1] and local_companies[company][-1] > 0]\n",
    "        if valid_companies:\n",
    "            random_company = random.choice(valid_companies)\n",
    "            local_companies[random_company][-1] -= 1\n",
    "            revenue += 1\n",
    "\n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c9378f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Greedy Algorithm...\n",
      "------------------------------------------------\n",
      "Trial 1 - Revenue generated: 9\n",
      "Trial 2 - Revenue generated: 12\n",
      "Trial 3 - Revenue generated: 8\n",
      "Trial 4 - Revenue generated: 10\n",
      "Trial 5 - Revenue generated: 8\n",
      "Trial 6 - Revenue generated: 7\n",
      "Trial 7 - Revenue generated: 10\n",
      "Trial 8 - Revenue generated: 8\n",
      "Trial 9 - Revenue generated: 7\n",
      "Trial 10 - Revenue generated: 9\n",
      "------------------------------------------------\n",
      "Average revenue generated for all trials:  8.8\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Greedy Algorithm...\")\n",
    "print(\"------------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = greedy_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"------------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fda97",
   "metadata": {},
   "source": [
    "#### 4.2. Balance Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9af1b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_algorithm(local_companies, queries):\n",
    "    # Initial revenue\n",
    "    revenue = 0\n",
    "    \n",
    "    # To-do! update revenue using balance algorithm\n",
    "    for word in queries:\n",
    "        valid_companies = [company for company in local_companies if word in local_companies[company][:-1] and local_companies[company][-1] > 0]\n",
    "        if valid_companies:\n",
    "            max_budget = 0\n",
    "            max_company = []\n",
    "            for company in valid_companies:\n",
    "                if local_companies[company][-1] > max_budget:\n",
    "                    max_company = [company]\n",
    "                    max_budget = local_companies[company][-1]\n",
    "                elif local_companies[company][-1] == max_budget:\n",
    "                    max_company.append(company)\n",
    "            if max_company:\n",
    "                selected_max_company = random.choice(max_company)\n",
    "                revenue += 1\n",
    "                local_companies[selected_max_company][-1] -= 1\n",
    "\n",
    "    # for word in queries:\n",
    "    #     valid_companies = [company for company in local_companies if word in local_companies[company][:-1] and local_companies[company][-1] > 0]\n",
    "    #     if valid_companies:\n",
    "    #         max_budget = 0\n",
    "    #         max_company = \"\"\n",
    "    #         for company in valid_companies:\n",
    "    #             if local_companies[company][-1] > max_budget:\n",
    "    #                 max_company = company\n",
    "    #                 max_budget = local_companies[company][-1]\n",
    "    #         if max_company:\n",
    "    #             revenue += 1\n",
    "    #             local_companies[max_company][-1] -= 1\n",
    "\n",
    "    \n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b975413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trials using Balance Algorithm...\n",
      "-------------------------------------------\n",
      "Trial 1 - Revenue generated: 10\n",
      "Trial 2 - Revenue generated: 9\n",
      "Trial 3 - Revenue generated: 9\n",
      "Trial 4 - Revenue generated: 8\n",
      "Trial 5 - Revenue generated: 8\n",
      "Trial 6 - Revenue generated: 9\n",
      "Trial 7 - Revenue generated: 9\n",
      "Trial 8 - Revenue generated: 10\n",
      "Trial 9 - Revenue generated: 9\n",
      "Trial 10 - Revenue generated: 9\n",
      "-------------------------------------------\n",
      "Average revenue generated for all trials:  9.0\n"
     ]
    }
   ],
   "source": [
    "total_revenue = 0\n",
    "total_trials = 10\n",
    "print(\"Starting trials using Balance Algorithm...\")\n",
    "print(\"-------------------------------------------\")\n",
    "for i in range(total_trials):\n",
    "    local_companies = copy.deepcopy(global_companies)\n",
    "    revenue = balance_algorithm(local_companies, queries)\n",
    "    total_revenue = total_revenue + revenue\n",
    "    print(f\"Trial {i+1} - Revenue generated: {revenue}\")\n",
    "print(\"-------------------------------------------\")   \n",
    "print(\"Average revenue generated for all trials: \",total_revenue/total_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2ef9e",
   "metadata": {},
   "source": [
    "### 5. Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86174f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings matrix (each row corresponds to a movie, and each column corresponds to a user)\n",
    "ratings_matrix = np.array([\n",
    "    [1, 0, 3, 0, 0, 5, 0, 0, 5, 0, 4, 0],\n",
    "    [0, 0, 5, 4, 0, 0, 4, 0, 0, 2, 1, 3],\n",
    "    [2, 4, 0, 1, 2, 0, 3, 0, 4, 3, 5, 0],\n",
    "    [0, 2, 4, 0, 5, 0, 0, 4, 0, 0, 2, 0],\n",
    "    [0, 0, 4, 3, 4, 2, 0, 0, 0, 0, 2, 5],\n",
    "    [1, 0, 3, 0, 3, 0, 0, 2, 0, 0, 4, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92e8e0",
   "metadata": {},
   "source": [
    "#### 5.1. User-User Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0749438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "import heapq\n",
    "\n",
    "def user_cf(rate_m, tup_mu, neigh):\n",
    "    \n",
    "    # To-do! implement a user-user CF using cosine similarity as distance measure\n",
    "    movie_num = tup_mu[0] - 1\n",
    "    user_num = tup_mu[1] - 1\n",
    "    sim_rating = {}\n",
    "\n",
    "    user_row = rate_m[:,user_num]\n",
    "    for i in range(len(rate_m[0])):\n",
    "        A = user_row\n",
    "        B = rate_m[:,i]\n",
    "        cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "        sim_rating[i] = cosine\n",
    "\n",
    "    N_highest = heapq.nlargest(neigh+1, sim_rating.items(), key=lambda item: item[1])\n",
    "    N_highest = N_highest[1:]\n",
    "\n",
    "    top = sum(rate_m[movie_num][index] * value for index,value in N_highest)\n",
    "    bottom = sum(value for _, value in N_highest)\n",
    "    \n",
    "    prediction = top / bottom\n",
    "    \n",
    "    return round(prediction,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c153de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuple of movie rating by users to be predicted e.g (1, 5) refers to the rating of movie 1 by user 5\n",
    "list_mu_query = [(1, 5), (3, 3)]\n",
    "\n",
    "# Neighbor selection (|N|)\n",
    "neigh = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22f8e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 1 by user 5: 1.42 (User-User CF)\n",
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 3 by user 3: 1.49 (User-User CF)\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = user_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (User-User CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217e4ed",
   "metadata": {},
   "source": [
    "#### 5.2. Item-Item Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c03be5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_cf(rate_m, tup_mu, neigh):\n",
    "    \n",
    "    # To-do! implement a item-item CF using cosine similarity as distance measure\n",
    "    movie_num = tup_mu[0] - 1\n",
    "    user_num = tup_mu[1] - 1\n",
    "    sim_rating = {}\n",
    "\n",
    "    movie_row = rate_m[movie_num]\n",
    "    for i in range(len(rate_m)):\n",
    "        A = movie_row\n",
    "        B = rate_m[i]\n",
    "        cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "        sim_rating[i] = cosine\n",
    "    \n",
    "    N_highest = heapq.nlargest(neigh+1, sim_rating.items(), key=lambda item: item[1])\n",
    "    N_highest = N_highest[1:]\n",
    "\n",
    "    top = sum(rate_m[index][user_num] * value for index,value in N_highest)\n",
    "    bottom = sum(value for _, value in N_highest)\n",
    "\n",
    "    prediction = top / bottom\n",
    "    \n",
    "    return round(prediction,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4b5ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 1 by user 5: 2.48 (Item-Item CF)\n",
      "-----------------------------------------------------------------\n",
      "The predicted rating of movie 3 by user 3: 3.0 (Item-Item CF)\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------------------------------------------------------\")   \n",
    "for mu_query in list_mu_query:\n",
    "    predicted_rating = item_cf(ratings_matrix, mu_query, neigh)\n",
    "    print(f\"The predicted rating of movie {mu_query[0]} by user {mu_query[1]}: {predicted_rating} (Item-Item CF)\")\n",
    "    print(\"-----------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892ce96",
   "metadata": {},
   "source": [
    "### Provide concise answers to all 5 cases in the Project 3 description below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc34aad",
   "metadata": {},
   "source": [
    "#### Case 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7c285",
   "metadata": {},
   "source": [
    "#### Question\n",
    "DGIM stores $O(\\log^2 N)$ bits rather than the entire window N. Knowing that the number of\n",
    "buckets used in the DGIM algorithm is log N, why then is the space complexity $O(\\log^2 N)$ rather than\n",
    "$O(\\log N)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0434a110",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "The space complexity of the DGIM algorithm is $O(\\log^2 N)$ rather than $O(\\log N)$. This is because we store $O(\\log^2 N)$ bits per window where N = Window Size. Given that the record stamps are in modula N (The window size), we can represent any relevant timestamps with $O(\\log^2 N)$ bits. Therefore we must have the space complexity of $O(\\log^2 N)$ in the DGIM algorithm rather than $O(\\log N)$, so that it will work properly and be able to save all relevant timestmaps and not miss any data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b85a6",
   "metadata": {},
   "source": [
    "#### Case 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99eb0bc",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "**1.** Your favorite social media platform uses Bloom filters to assign new usernames. When\n",
    "you try to obtain a new username, ’Kazeem,’ it says, \"username is taken.\" Is there a possibility that the username is available? If yes, how do you present your case to the site admin?\n",
    "\n",
    "**2.** After a bit of ingenuity on your part, you finally came up with ’KazeemTDT4305\", and fortunately, it says this is available. However, a friend sitting next to you prompted that they know a friend of a friend that has this exact username on the same platform. Is this possible? Knowing that this friend has never taken a CS course on Big Data and has probably always doubted your brilliance. Clearly, this is the moment you have been waiting for to brandish your TDT4305 Big Data prowess. How can you effectively convince your friend that he is mistaken?\n",
    "\n",
    "**3. While you are at it, show a bit of altruism by solving this case for a Google user Google Support Center:**\n",
    "\n",
    "I am trying to create an account and when I use my daughter's first.last@gmail.com, google says that account is taken. I found that hard to believe so I emailed the account and sure enough, it bounced back saying no such user.\n",
    "\n",
    "Any idea why this is and how I can contact google to make an exception?\n",
    "\n",
    "I was able to do this for my son, but not for my daughter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45faf977",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "**1.** Yes, when using Bloom Filters there is a possibility that the username is still available even though it says it is taken. That it because of the hashing method of the bloom filters they can have false positives but no false negatives. This is so that there will be no duplicate username by mistake. It could also be because of the hashing method and there is a username that is similar, then becuase of the no false negatives method in the bloom filters, it will say the username is taken\n",
    "\n",
    "**2.** As said above, bloom filters work by first hashing each letter/number value in you username, sum up the hashed values and indexes them. This way, Bloom filters can never have any false positives (That it says that the username is available when it is not available). Because when it checks if the username is available or not, it hashes the username and checks the index number. If it is 0 at the index number then it is available, if it is 1 then it is not available. This way it checks much faster, although it could be that you username is available when it says it is not available, because we only check the hash values index number and not the username.\n",
    "\n",
    "**3.** It says that your username is taken because of the way Google checks already made usernames. That means that there is another username (that is different) but has the same \"Google Value\" as yours. So the fastest way is to add a number at the end of the name. Then it will get another \"Google Value\" that will most likely be available. If not then just get in touch with Google, so they can manually check if the username is taken or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16cad2",
   "metadata": {},
   "source": [
    "#### Case 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b60fd",
   "metadata": {},
   "source": [
    "#### Question\n",
    "How do we increase precision while using the Flajolet-Martin algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3766ad9",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "You can increase the precision by grouping hash functions, take median of value obtained in each group and then the average value obtained across groups.\n",
    "You can also repeat many times and compute in parallel for multiple hash functions. This will lead to a more precise Flajolet-Martin algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9e628",
   "metadata": {},
   "source": [
    "#### Case 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2745f",
   "metadata": {},
   "source": [
    "#### Question\n",
    "What is the minimum and maximum possible revenue, and the competitive ratio of both the\n",
    "Greedy and Balance algorithm for the input data provided in the Notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aeff6a",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "To answer this question, we write a code that runs both algorithms 100 times and returns the minimum/maximum value and competitive ratio as given with the Competitive Ratio Equitation:\n",
    "$$\n",
    "\\text{Competitive ratio} = \\min_{\\text{all possible inputs}} \\left( \\frac{|M_{\\text{greedy}}|}{|M_{\\text{opt}}|} \\right)\n",
    "$$\n",
    "\n",
    "#### Greedy Algorithm Results:\n",
    "\n",
    "*   **Maximum Value**: 11\n",
    "*   **Minimum Value**: 6\n",
    "*   **Competitive Ratio**: $$ \\frac{6}{12} = \\frac{1}{2} = 0.5 $$\n",
    "\n",
    "#### Balance Algorithm Results:\n",
    "\n",
    "*   **Maximum Value**: 10\n",
    "*   **Minimum Value**: 8\n",
    "*   **Competitive Ratio**: $$ \\frac{8}{12} = \\frac{2}{3} \\approx 0.667 $$\n",
    "\n",
    "P.S. Chose to run it 100 times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c341065",
   "metadata": {},
   "source": [
    "#### Case 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade90a44",
   "metadata": {},
   "source": [
    "#### Question\n",
    "Observe the rating matrix, based on intuition, which gave a better prediction for movie 1 and user 5 rating between User-User CF and Item-Item CF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348752fa",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n",
    "**User-User Collaborative Filtering (CF):**\n",
    "\n",
    "- Predicted rating of movie 1 by user 5: **1.42**\n",
    "\n",
    "**Item-Item Collaborative Filtering (CF):**\n",
    "\n",
    "- Predicted rating of movie 1 by user 5: **2.48**\n",
    "\n",
    "**Input Matrix:**\n",
    "\n",
    "```\n",
    "[1, 0, 3, 0, 0, 5, 0, 0, 5, 0, 4, 0],\n",
    "[0, 0, 5, 4, 0, 0, 4, 0, 0, 2, 1, 3],\n",
    "[2, 4, 0, 1, 2, 0, 3, 0, 4, 3, 5, 0],\n",
    "[0, 2, 4, 0, 5, 0, 0, 4, 0, 0, 2, 0],\n",
    "[0, 0, 4, 3, 4, 2, 0, 0, 0, 0, 2, 5],\n",
    "[1, 0, 3, 0, 3, 0, 0, 2, 0, 0, 4, 0]\n",
    "```\n",
    "\n",
    "When looking at the Input Matrix we can see that User 5 has the most similarity as User 3. And smaller similarities with User 4 and 7. Aswell as User 5 has the most difference with user 6 and 11. User 3 has rated the movie a 3 and User 4 and 7 has not rated the movie yet. User 6 and 11 has rated the movie a 5 and 4. With this is knowledge, aswell as the knowledge that User 4 and 7 has not rated the movie yet, then the Item-Item CF is the more acurate prediction, given with only my intuition and zero mathematical proff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
